---
title: "biopixR - Tools for Biological Image Processing and Analysis"
author: "Tim Brauckhoff"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    fig_caption: yes
    toc: FALSE
    toc_depth: 3
    fontsize: 12pt
    latex_engine: xelatex
csl: european-journal-of-taxonomy.csl
link-citations: yes
urlcolor: Blue
linkcolor: Blue
always_allow_html: TRUE
bibliography: lib-vig.bib
header-includes:
  \usepackage{float}
  \usepackage[onehalfspacing]{setspace}
  \usepackage[]{hyperref}
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  cache = FALSE,
  comment = NA,
  verbose = TRUE
)
original_options <- options()
options(digits = 3)

library(knitr)
library(foodwebr)
library(biopixR)
```

\tableofcontents

\pagebreak

```{r, echo=FALSE, fig.align='center', out.width="69%", fig.show='hold', fig.pos="ht"}
include_graphics("figures/fig0_logo.png")
```


# Aims of the `biopixR` package

# Introduction to Object Quantification in Biological Images

## Techniques in Bioimage Informatics for Feature detection

### Why is there a need for the `biopixR` package?

# Concepts and Methods

## Development, Implementation and Installation

```{r, eval=FALSE}
foodweb(biopixR::imgPipe) |> plot()
```

```{r, echo=FALSE, fig.show='hold', fig.align='center', out.width="99%", fig.pos="ht"}
include_graphics("figures/fig4_dependency.png")
```

The core contributors are listed in the `DESCRIPTION` file of the `biopixR` package. The following paragraphs describe methods applied for the `biopixR` package.

### Version Control and Continous Integration

For the purpose of version control, the widely used Git system, which is
available on all major development platforms, was employed. Version control with
Git enables the revision of changes and older versions of the code by providing
complete repository copies. Additionally, it permits individual adaptation by
creating distinct "branches" for the purpose of working on and experimenting
with different versions while maintaining a stable one. Most importantly, it
facilitates the organized sharing and merging of changes among team members,
thereby significantly enhancing collaboration [@Lanubile2010; @Blischak2016;
@Vuorre2018].

GitHub, a Git repository hosting provider, offers a web-based user interface to
facilitate collaboration in open source projects. It incorporates tools for the
reporting of bugs (Issues), collaboration (Pull requests), and workflows
(Actions) [@Spinellis2012; @Cosentino2016; @PerezRiverol2016]. The source code
of the `biopixR` package is accessible at:

\phantom{x}\hspace{0.75cm} https://github.com/Brauckhoff/biopixR

Continuous integration (CI) is widely regarded as a good practice in software
development. As team members frequently integrate their code, sometimes multiple
times a day, the combination of code from different contributors can lead to
significant issues in the software's integrity and functionality. To address
this issue, CI is employed as an automated build and test system. It verifies
the package's functionality and compatibility across various operating systems
(OS). This ensures that the code, package structure, metadata, and format remain
functional. This process of error catching is simplified by CI, as it is able to
identify potential issues in the integration process [@Meyer2014; @Soares2022].

For `R`, the standard test suite is the `R CMD check`, which includes over 50
individual checks. These tests encompass a range of topics, including metadata
validation, package structure, `DESCRIPTION` files, Namespace, `R` code, and
documentation.^[https://r-pkgs.org/r-cmd-check.html] The `R CMD check`
workflow for the `biopixR` package, based on the work of @Hester2021, involves
testing across all major operating systems. The tests were conducted on Windows,
macOS, and Linux. Furthermore, the developer version of `R` was tested on the
Linux operating system. The source code for the CI setup using GitHub workflows, 
as well as the test history can be accessed at:

\phantom{x}\hspace{0.75cm} https://github.com/Brauckhoff/biopixR/actions/workflows/R-CMD-check.yml


### Naming Convention and Literate Programming

`biopixR` is an `R` package ($\ge$ 4.2.0), designed using the S3 object system.
S3 incorporates object-oriented programming features while simplifying
development through naming conventions [@Chambers2014]. Typically, functions
and parameters in R packages are written using underscore separation
[@Rasmus2012]. However, for the purpose of differentiation, this convention
was adapted. Underscore separation is employed solely for variables and
parameters introduced within the package. In accordance with the nomenclature
convention proposed by @Rasmus2012, the functions of the `biopixR` package
adhere to the **lowerCamelCase** style (e.g., `objectDetection()`), with the
exception of those designated to be interactive, which also utilize the
**underscore_separated** style (e.g., `interactive_objectDetection()`).

In order to enhance the formatting, consistency, and readability of the code,
the `styler` package by @Mueller2017 was employed and applied to the code. The
`styler` package performs "non-invasive pretty printing of R code", whereby the
code is formatted according to the [*tidyverse style guide*](https://style.tidyverse.org/).

Literate programming, introduced by @Knuth1984, combines source code and
documentation in a single file. This approach uses markup conventions (e.g.,
'#') to format the documentation, generating outputs in typesetting
languages like **Markdown**. Literate programming is crucial for ensuring
reproducibility of analysis in software development [@Vassilev2016].
Additionally, inline code annotations have been added to every function in the
`biopixR` package.

The `roxygen2`, `rmarkdown`, and `knitr` packages were employed to write the
documentation inline with the code for the `biopixR` package.


### Installation of the `biopixR` package

The ongoing developments will be consistently updated in the GitHub repository.
Consequently, the latest developer version of the `biopixR` package can be
accessed and downloaded directly from the repository using the `devtools`
package.

```{r, eval=FALSE}
# Install the 'devtools' package from CRAN.
# 'devtools' is required for installing R packages directly from GitHub repositories.
install.packages("devtools")

# Install the 'biopixR' package from a GitHub repository.
# 'install_github' is a function in 'devtools' that is used to install R packages
# hosted on GitHub.
# The argument "Brauckhoff/biopixR" specifies the GitHub username/repo of the package.
devtools::install_github("Brauckhoff/biopixR")
```

The `biopixR` package is available on The **C**omprehensive **R** **A**rchive
**N**etwork (CRAN), which can be accessed at
[https://CRAN.R-project.org/package=biopixR]. CRAN employs rigorous testing
procedures to ensure that the package can be downloaded and built on all major
operating systems. Additionally, it validates the examples and documentation
through the `R CMD check`. In order to utilize the `biopixR` package, it is
first necessary to install R (version 4.2.0 or higher) and then to execute the
following code:

```{r, eval=FALSE}
# Install the 'biopixR' package from the Comprehensive R Archive Network (CRAN).
install.packages("biopixR")
```

The results of the R CMD check conducted by CRAN can be accessed via the
following link:
[https://cran.r-project.org/web/checks/check_results_biopixR.html]

### Unit Testing of the `biopixR` Package

https://dl.acm.org/doi/abs/10.1145/267580.267590
https://ieeexplore.ieee.org/abstract/document/9402000

Myers2012
https://malenezi.github.io/malenezi/SE401/Books/114-the-art-of-software-testing-3-edition.pdf

`testthat` package by @Wickham2011.https://svn.r-project.org/Rjournal/html/archive/2011-1/RJournal_2011-1_Wickham.pdf


## Functions for Quantitative Data Analysis in `biopixR`

The `biopixR` package includes a series of microbead images in order to
demonstrate its capabilities in the analysis and processing of biological
imagery. The sample images illustrate the package's functionalities, allowing
users to explore and experiment with image analysis and manipulation within the
context of biotechnology and life sciences. Researchers and practitioners may
utilize these illustrations to comprehend the applicability of `biopixR` to
their particular imaging requirements, whether pertaining to cell biology,
microscopy, or other biological imaging applications.

(ref:examples) **Examples**: Images of microbeads provided by the `biopixR` package.

```{r examples, echo=FALSE, fig.cap="(ref:examples)", out.width="99%", fig.show='hold', fig.pos="ht"}
# Load the biopixR package
library(biopixR)

# Set up a 2x2 plotting area
par(mfrow = c(2, 2))

# Plot example images without axes and with a title
plot(beads, axes = FALSE, main = "beads")
plot(beads_large1, axes = FALSE, main = "beads_large1")
plot(beads_large2, axes = FALSE, main = "beads_large2")
plot(droplet_beads, axes = FALSE, main = "droplet_beads")

# Reset the plotting area to a single plot
par(mfrow = c(1, 1))
```

A selection of these images will be employed in the forthcoming demonstration of
the `biopixR` functions.

### `importImage()` - Importing Images into the R Environment

The `biopixR` package features an import function called `importImage()`. This
function acts as a wrapper, integrating the capabilities of the `magick` and
`imager` packages. Since most image processing operations rely on `imager`, the
`importImage` function converts all formats into the `imager` class 'cimg'. It
was frequently observed that images exhibited more than three dimensions within
the color channel, specifically an additional transparency layer, also called
alpha. Such images frequently give rise to challenging and elusive errors. To
address this issue, the `imageImport()` function employs a process of detection
and removal of a fourth color dimension, should it be present. The function
supports importing images in JPEG, PNG, BMP, and TIFF formats.

```{r}
# Get the path to the "beads.png" image file within the `biopixR` package
path2img <- system.file("images/beads.png", package = "biopixR")

# Import the image from the path specified by 'path2img' and store it in the 
# 'microbeads' object
microbeads <- importImage(path2img)

# Import the image "fig6.1_transparent.bmp" from the "figures" directory and 
# store it in the 'transparent_bead' object
transparent_bead <- importImage("figures/fig6.1_transparent.bmp")

# Display the class of the 'microbeads' object
class(microbeads)
```

(ref:beads) **Example images**: Showcasing the functionality of the function for image import - `importImages()`.

```{r beads, fig.align='center', fig.show='hold', out.width="99%", fig.cap="(ref:beads)", fig.pos="ht"}
# Set up a 1x2 plotting area
par(mfrow = c(1, 2))

# Display imported images
plot(microbeads, axes = FALSE)
plot(transparent_bead, axes = FALSE)

# Reset the plotting area to a single plot
par(mfrow = c(1, 1))
```


### `edgeDetection()` - A modified Canny edge Detector

A variety of edge detection algorithms are available in the `R` programming
language, with the Canny edge detector, developed by @Canny1986, being the most
widely implemented across multiple packages, including those by @Barthelme2015;
@Ooms2016; @Mouselimis2016; and @Beare2018. Other noteworthy edge detectors in
the `R` package `OpenImageR` include those by @Prewitt1970, @Sobel2014,
@Roberts1980, and @Scharr2000 [@Mouselimis2016]. After evaluating the
different results (exemplary see \@ref(fig:compare)), the Canny edge detection
algorithm from the `imager` package was selected for edge detection. The
resulting binary image serves as a foundation for subsequent feature detection.
Furthermore, the `cannyEdges()` function in `imager` offers adjustable
parameters for alpha and sigma, enabling users to customize thresholding and
smoothing, providing the desired flexibility.

The process of Canny edge detection using the `imager` package is comprised of a
series of steps. Initially, a Gaussian filter is applied to the image, resulting
in the smoothing of the image in order to remove noise. The degree of smoothing
can be adjusted by varying the value of the `sigma` parameter. Subsequently, the
intensity gradient is calculated in order to determine the magnitude of the
edges. This is followed by the application of non-maximum suppression, which
serves to minimize the blur introduced previously. Subsequently, a double
threshold is applied. In the absence of provided thresholds, they are estimated
through k-means clustering. The calculated threshold can be adjusted using the
`alpha` parameter. These thresholds are employed to classify edges as either
weak or strong. Finally, hysteresis is employed to integrate these edges, with
weak edges being discarded if they are not in proximity to strong edges
[@Barthelme2015; @Barthelme2019].^[http://dahtah.github.io/imager/canny.html]

(ref:compare) **Comparison of Two Edge Detection Algorithms**: **A**) Resulting image using the @Prewitt1970 edge detection algorithm from the `OpenImageR` package. The contours have higher intensity, but the image is not binary. **B**) The Canny edge detection algorithm produces a binary image with distinct contours.

```{r, eval=FALSE}
# Set up a 1x2 plotting area
par(mfrow = c(1, 2))

OpenImageR::edge_detection(as.matrix(beads), method = "Prewitt") |> as.cimg() |> plot(axes = FALSE, main = "Prewitt - edge detection", cex.main = 2)
text(c(7.5), c(7.5), c("A"), col = "darkred", cex = 3.5)

cannyEdges(beads) |> plot(axes = FALSE, main = "Canny - edge detection", cex.main = 2)
text(c(7.5), c(7.5), c("B"), col = "darkred", cex = 3.5)

# Reset the plotting area to a single plot
par(mfrow = c(1, 1))
```

```{r compare, echo = FALSE, fig.show='hold', fig.align='center', out.width="99%", fig.pos="ht", fig.cap="(ref:compare)"}
include_graphics("figures/fig5.1_edgeDetection.png")
```

In the context of microbead images, the contours that were identified frequently
exhibited gaps, rendering them inaccessible for subsequent labeling (see
\@ref(fig:cannyE)A). The figure depicts filled circles representing successfully
labeled microbeads, while the contours indicate unsuccessful labeling.
Consequently, segmentation with fragmented contours is incomplete, rendering the
objects inaccessible for further analysis. To address this issue, the `magick`
package was employed to identify line ends (see \@ref(fig:cannyE)B). Line ends
can then be reconnected to a neighboring line, provided that the line end does
not share the same label. This process of reconnection is constrained by a
specific radius in order to prevent line ends from connecting across the entire
image.

(ref:cannyE) **Segmentation Result with Canny Edge Detector**: **A**) Segmentation result using the `label()` function. The segmentation is incomplete, as not all microbeads are identified as foreground. Only the contours are detected in these cases (highlighted by red arrows). **B**) Result of the `cannyEdges()` function, showing detected line end pixels, which are colored and circled in green.

```{r, eval=FALSE}
# Set up the plotting area to have 1 row and 2 columns
par(mfrow = c(1, 2))

# Apply Canny edge detection to the image 'beads_large1' with specified parameters
edge_canny <- cannyEdges(beads_large1, alpha = 0.8, sigma = 0)

# Label the detected edges
labeled_canny <- label(edge_canny)

# Plot the labeled edges without axes
plot(labeled_canny, axes = FALSE)

# Add a text label "A" in dark red color at coordinates (475, 360)
text(c(475), c(360), c("A"), col = "darkred", cex = 4)

# Draw red arrows at specified coordinates
arrows(
  x0 = 23,
  y0 = 29,
  x1 = 24,
  y1 = 30,
  col = "red",
  lwd = 2
)
arrows(
  x0 = 412,
  y0 = 148,
  x1 = 413,
  y1 = 147,
  col = "red",
  lwd = 2
)
arrows(
  x0 = 73,
  y0 = 210,
  x1 = 72,
  y1 = 210,
  col = "red",
  lwd = 2
)

# Mirror the detected edges across the x-axis
edge_canny_m <- mirror(edge_canny, axis = "x")

# Convert the mirrored edge image to magick format
canny_magick <- cimg2magick(edge_canny_m)


# Detect the coordinates of all line ends using morphology operation
lineends_canny <- image_morphology(canny_magick,
                                   "HitAndMiss", "LineEnds")

# Convert the extracted coordinates back into 'cimg' format
lineends_cimg <- magick2cimg(lineends_canny)

# Find the coordinates of the line ends and transform into a data frame
end_points <- which(lineends_cimg == TRUE, arr.ind = TRUE)
end_points_df <- as.data.frame(end_points)
colnames(end_points_df) <- c("x", "y", "dim3", "dim4")

# Highlight the line end pixel in green color on the original edge image
endpoints_img <- changePixelColor(as.cimg(edge_canny),
                                  end_points_df,
                                  color = "green",
                                  visualize = FALSE)

# Plot the image with highlighted line ends without axes
plot(endpoints_img, axes = FALSE)

# Highlight the line ends in green color on the original edge image
points(end_points_df$x, end_points_df$y, col = "green")

# Draw red arrows at specified coordinates
arrows(
  x0 = 23,
  y0 = 29,
  x1 = 24,
  y1 = 30,
  col = "red",
  lwd = 2
)
arrows(
  x0 = 412,
  y0 = 148,
  x1 = 413,
  y1 = 147,
  col = "red",
  lwd = 2
)
arrows(
  x0 = 73,
  y0 = 210,
  x1 = 72,
  y1 = 210,
  col = "red",
  lwd = 2
)

# Add a text label "B" in dark red color at coordinates (475, 360)
text(c(475), c(360), c("B"), col = "darkred", cex = 4)

# Set up the plotting area back to normal
par(mfrow = c(1, 1))
```

```{r cannyE, echo = FALSE, fig.show='hold', fig.align='center', out.width="99%", fig.cap="(ref:cannyE)", fig.pos="ht"}
include_graphics("figures/fig5_edgeDetection.png")
```

As illustrated in \@ref(fig:edgeD)A, the modified Canny edge detector,
`edgeDetection()`, is capable of successfully rejoining line ends, thereby
enabling the detection of previously unlabeled microbeads, as shown in
\@ref(fig:cannyE)A. For further visualization, the `objectDetection()` function
was employed. This function employs the `edgeDetection()` function and provides
visual feedback as an output (\@ref(fig:edgeD)B).

(ref:edgeD) **Segmentation Result with Modified Canny Edge Detector**: **A**) Segmentation result using the `label()` function, showing successful segmentation with all microbeads identified as part of the foreground. **B**) Successful segmentation visualized using the `objectDetection()` function, with purple contours around each microbead and green dots indicating their centers.

```{r, eval = FALSE}
# Set up a 1x2 plotting area
par(mfrow = c(1, 2))

# Detect objects in the 'beads_large1' image using the edge method with 
# specified alpha and sigma values
object_biopixR <-
  objectDetection(beads_large1,
                  method = 'edge',
                  alpha = 0.8,
                  sigma = 0)

# Perform edge detection on the 'beads_large1' image with specified alpha and 
# sigma values
edge_biopixR <- edgeDetection(beads_large1, alpha = 0.8, sigma = 0)

# Label the detected edges in the 'edge_biopixR' image
labeled_biopixR <- label(edge_biopixR)

# Plot the labeled edges without axes
plot(labeled_biopixR, axes = FALSE)

# Add text "A" to the plot at coordinates (475, 360) with dark red color and size 4
text(c(475), c(360), c("A"), col = "darkred", cex = 4)

# Plot the marked objects from the object detection without axes
plot(object_biopixR$marked_objects, axes = FALSE)

# Add text "B" to the plot at coordinates (475, 360) with dark red color and size 4
text(c(475), c(360), c("B"), col = "darkred", cex = 4)

# Reset the plotting area to a single plot
par(mfrow = c(1, 1))
```

```{r edgeD, echo = FALSE, fig.show='hold', fig.align='center', out.width="79%", fig.cap="(ref:edgeD)", fig.pos="ht"}
include_graphics("figures/fig5.2_edgeDetection.png")
```


### `objectDetection()` Function to detect Microbeads in an Image




```{r, eval=FALSE}
par(mfrow = c(1,2))
transparant_beads <- importImage("figures/fig6_transparent_beads.bmp")
plot(transparant_beads, axes = FALSE)
text(c(80), c(80), c("A"), col = "darkred", cex = 5)
result_transparant <- objectDetection(transparant_beads, method = 'threshold')
plot(result_transparant$marked_objects, axes=FALSE)
text(c(80), c(80), c("B"), col = "darkred", cex = 5)
par(mfrow = c(1,1))
```
(ref:transparent) **Transparent microbeads**:

```{r transparent, echo=FALSE, fig.cap="(ref:transparent)", out.width="99%", fig.pos="ht"}
include_graphics("figures/fig7_transparent_beads.png")
```



```{r, eval=FALSE}
interactive_objectDetection(beads_large1)
```

```{r, echo=FALSE, out.width="99%", fig.pos="ht"}
include_graphics("figures/fig8_GUI.png")
```


### Dealing with Autofluorescence and Clotting with `sizeFilter()` and `proximityFilter()`

### Interpretation with `resultAnalytics()`

## Batch proccesing Functions within the `biopixR` package

This section introduces two pipeline functions. The first is `imgPipe`, which integrates multiple functions from the `biopixR` package, allowing for the comprehensive analysis and filtering of an image within a single function. The second function, `scanDir`, is an extension of `imgPipe` designed for batch processing. It enables the analysis of entire directories with all the options, parameter adjustments, and individual filtering capabilities offered by `imgPipe`.

### `imgPipe()`: One image One function 

The `imgPipe()` function integrates various functions into a single streamlined pipeline, including `objectDetection()`, `sizeFilter()`, `proximityFilter()`, and `resultsAnalytics()`. It is designed to process multiple color channels simultaneously. For instance, if an image contains objects of two different colors, with each color detectable in separate channels, these two images can be input into the `imgPipe()` function. The function will then analyze both images and combine the results, providing a summary of the number of objects detected in each image. This feature is particularly useful for analyzing dual-colored microbeads.

In the following example, the 'edge' method (edge detection) is utilized. Parameters such as alpha and sigma need to be specified, and the `sizeFilter()` is enabled to exclude doublets and multiplets from the analysis.

```{r imgPipe1}
res_pipe <- imgPipe(beads_large1,
                    method = 'edge',
                    alpha = 0.7,
                    sigma = 0.1,
                    sizeFilter = TRUE,
                    upperlimit = 'auto',
                    lowerlimit = 'auto')

# Create data for the visualization of lower and upper limit
res_comp <- objectDetection(beads_large1, method = 'edge', alpha = 0.7, sigma = 0.1)
```

The remaining microbeads are highlighted in different colors to distinguish between individual objects. Alongside the image, a plot is provided showing the calculated size limits.

```{r imgPipe2, fig.show='hold', out.width="99%", fig.align='center', fig.pos="ht"}
par(mfrow = c(1,2))

plot(beads_large1, axes = FALSE)
points(res_pipe$detailed$x,
       res_pipe$detailed$y,
       pch = 19,
       col = factor(res_pipe$detailed$objectnumber))

plot(res_comp$centers$size, ylab = "size in px")
abline(h = c(85, 109))

par(mfrow = c(1,1))
```

### `scanDir()`

## Functions for Droplet Analysis

### Dealing with discontinous edges

### `fillLineGaps()` - 

## Shape, Texture and unsupervised Machine Learning

### `shapeFeatures()` - Object clustering based on shape features

```{r}
circles <- importImage("figures/fig3_analysis_circ.png")
circles <- grayscale(circles)

shapes <- shapeFeatures(circles, alpha = 1, sigma = 0) 
```

```{r, echo=FALSE}
seven <- shapes[6, 2:12]
six <- shapes[7, 2:12]

shapes[6, 2:12] <- six
shapes[7, 2:12] <- seven
```

```{r, echo=FALSE, fig.show='hold', fig.align='center', out.width="79%", fig.pos="ht"}
knitr::include_graphics("figures/fig2_circularity.png")
```

```{r, echo=FALSE}
data <- shapes[, c(1,8:12)]

kable(
  data,
  col.names = c(
    "objectnumber",
    "circularity",
    "eccentricity",
    "mean radius",
    "sd radius",
    "aspect ratio"
  ),
  caption = "Comparison of Aspect Ratios"
)
```

```{r, echo=FALSE, out.width="79%", fig.align='center', fig.show='hold', fig.pos="ht"}
truth <- data.frame(index = seq_len(nrow(shapes)),
                    AR = c(1, 10/9, 10/8, 10/7, 10/6, 2, 10/4, 10/3, 5, 10))

plot(truth$index, truth$AR, main = "Comparison of Dataframes",
     xlab = "Objectnumber", ylab = "Aspect Ratio", pch = 19, col = "blue")

# Add points from the second dataframe for comparison
points(shapes$objectnumber, shapes$aspect_ratio, pch = 20, col = "green")

# Add a legend to the plot
legend("topleft", legend = c("Dataframe 1", "Dataframe 2"),
       col = c("blue", "green"), pch = c(19, 20))
```



### `HaralickCluster()` - Image classification based on texture features

```{r haralickCluster2}
path2dir <- system.file("images", package = "biopixR")

img_clus <- haralickCluster(path2dir)
```

```{r, echo=FALSE}
file_paths <- img_clus$file
new_file_paths <- sapply(file_paths, function(x) gsub("brauctim", "user", x))
img_clus$file <- new_file_paths
```

```{r haralickCluster3}
img_clus
```

```{r, echo=FALSE, out.width="99%", fig.show='hold', fig.align='center', fig.pos="ht"}
include_graphics(
  c(
    "figures/1update.png",
    "figures/2update.png",
    "figures/3update.png",
    "figures/4update.png"
  )
)
```



## Helper Functions of the `biopixR` Package

- `interpolatePixels()`
- `adaptiveInterpolation()`
- `changePixelColor()`

# Discussion



# Summary and Conclusion


# Outlook

```{r eval=FALSE}
# Import the image from the specified file path
img <- importImage("figures/tim_242602_c_s6c1+2+3m3.tif")

# Plot the imported image without axes
plot(img, axes = FALSE)

# Add a text annotation "A" at coordinates (50, 60) with dark red color and size 6
text(c(50), c(60), c("A"), col = "darkred", cex = 6)

# Extract the green channel from the image (assuming the image has multiple color channels)
img_g <- img[, , , 2]

# Convert the green channel to a 'cimg' object for further processing
cimg_g <- as.cimg(img_g)

# Perform object detection on the green channel image using the 'edge' method
# with specified parameters alpha and sigma
detected <-
  objectDetection(cimg_g,
                  method = 'edge',
                  alpha = 1.3,
                  sigma = 0)

# Change the pixel colors of the detected objects
colored_objects <-
  changePixelColor(cimg_g,
                   detected$coordinates,
                   color = factor(detected$coordinates$value),
                   vis = FALSE)

# Plot the image with colored objects without axes
plot(colored_objects, axes = FALSE)

# Add a text annotation "B" at coordinates (50, 60) with dark red color and size 6
text(c(50), c(60), c("B"), col = "darkred", cex = 6)
```

```{r, echo=FALSE, fig.show='hold', fig.align='center', out.width="99%", fig.pos="ht"}
knitr::include_graphics("figures/fig1_DSB_analysis.png")
```


# Acknowledgement



\pagebreak

```{r}
sessionInfo()
```

\pagebreak

# References
